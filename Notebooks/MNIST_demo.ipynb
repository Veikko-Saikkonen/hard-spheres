{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hard spheres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic\n",
    "from IPython.display import display\n",
    "\n",
    "# For OS-agnostic paths\n",
    "from pathlib import Path\n",
    "\n",
    "# Plotting\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import torch\n",
    "from torch import nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "sns.set_style(\"whitegrid\")\n",
    "from copy import deepcopy\n",
    "import glob, json\n",
    "from datetime import datetime\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "from torchinfo import summary\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load MNIST\n",
    "\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "def load_mnist():\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,), (0.5,))\n",
    "    ])\n",
    "\n",
    "    trainset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=True, transform=transform)\n",
    "    testset = datasets.MNIST('~/.pytorch/MNIST_data/', download=True, train=False, transform=transform)\n",
    "    \n",
    "    return trainset, testset\n",
    "\n",
    "trainset, testset = load_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mock data\n",
    "\n",
    "Make the digit (label) the input based on which the gan generates data.\n",
    "\n",
    "The goal is to train the gan to generate images of the digit that is fed as the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the digit (label) the input based on which the gan generates data.\n",
    "\n",
    "# The goal is to train the gan to generate images of the digit that is fed as the input.\n",
    "\n",
    "class MNISTLabelDataset(Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, label = self.dataset[idx]\n",
    "        return label, image\n",
    "    \n",
    "trainset = MNISTLabelDataset(trainset)\n",
    "testset = MNISTLabelDataset(testset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5,\n",
       " tensor([[[-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.9765, -0.8588,\n",
       "           -0.8588, -0.8588, -0.0118,  0.0667,  0.3725, -0.7961,  0.3020,\n",
       "            1.0000,  0.9373, -0.0039, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -0.7647, -0.7176, -0.2627,  0.2078,  0.3333,  0.9843,\n",
       "            0.9843,  0.9843,  0.9843,  0.9843,  0.7647,  0.3490,  0.9843,\n",
       "            0.8980,  0.5294, -0.4980, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -0.6157,  0.8667,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "            0.9843,  0.9843,  0.9843,  0.9686, -0.2706, -0.3569, -0.3569,\n",
       "           -0.5608, -0.6941, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -0.8588,  0.7176,  0.9843,  0.9843,  0.9843,  0.9843,  0.9843,\n",
       "            0.5529,  0.4275,  0.9373,  0.8902, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -0.3725,  0.2235, -0.1608,  0.9843,  0.9843,  0.6078,\n",
       "           -0.9137, -1.0000, -0.6627,  0.2078, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -0.8902, -0.9922,  0.2078,  0.9843, -0.2941,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000,  0.0902,  0.9843,  0.4902,\n",
       "           -0.9843, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -0.9137,  0.4902,  0.9843,\n",
       "           -0.4510, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.7255,  0.8902,\n",
       "            0.7647,  0.2549, -0.1529, -0.9922, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.3647,\n",
       "            0.8824,  0.9843,  0.9843, -0.0667, -0.8039, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -0.6471,  0.4588,  0.9843,  0.9843,  0.1765, -0.7882, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -0.8745, -0.2706,  0.9765,  0.9843,  0.4667, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000,  0.9529,  0.9843,  0.9529, -0.4980,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -0.6392,  0.0196,  0.4353,  0.9843,  0.9843,  0.6235, -0.9843,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.6941,  0.1608,\n",
       "            0.7961,  0.9843,  0.9843,  0.9843,  0.9608,  0.4275, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -0.8118, -0.1059,  0.7333,  0.9843,\n",
       "            0.9843,  0.9843,  0.9843,  0.5765, -0.3882, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -0.8196, -0.4824,  0.6706,  0.9843,  0.9843,  0.9843,\n",
       "            0.9843,  0.5529, -0.3647, -0.9843, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -0.8588,\n",
       "            0.3412,  0.7176,  0.9843,  0.9843,  0.9843,  0.9843,  0.5294,\n",
       "           -0.3725, -0.9294, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -0.5686,  0.3490,  0.7725,\n",
       "            0.9843,  0.9843,  0.9843,  0.9843,  0.9137,  0.0431, -0.9137,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000,  0.0667,  0.9843,  0.9843,\n",
       "            0.9843,  0.6627,  0.0588,  0.0353, -0.8745, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000],\n",
       "          [-1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000,\n",
       "           -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000, -1.0000]]]))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fa292cb57c0>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Visualize a sample\n",
    "\n",
    "label, image = trainset[0]\n",
    "print(label)\n",
    "plt.imshow(image.squeeze().numpy(), cmap='gray')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64])\n",
      "torch.Size([64, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "for digit, real_images in DataLoader(trainset, batch_size=64, shuffle=True):\n",
    "    print(digit.shape)\n",
    "    print(real_images.shape)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, channels_img=3, features_d=64):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.disc = nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                channels_img, features_d, kernel_size=3\n",
    "            ),  # 32x32\n",
    "            nn.LeakyReLU(0.2),\n",
    "            self._block(features_d, features_d * 2, 4),  # 16x16\n",
    "            self._block(features_d * 2, features_d * 4, 4,),  # 8x8\n",
    "            self._block(features_d * 4, features_d * 8, 4),  # 4x4\n",
    "            nn.Conv2d(features_d * 8, 1, kernel_size=3),  # 1x1\n",
    "            nn.Flatten(),\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "        self.out = nn.Sequential( # This is the output layer that will take the output of the discriminator and the digit and make a decision whether the image is real or fake\n",
    "            nn.Linear(226,128), # 225 + 1 for digit\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(128,64), # 225 + 1 for digit\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(64,1), # 225 + 1 for digit\n",
    "            nn.Sigmoid(),\n",
    "        )\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size):\n",
    "        return nn.Sequential(\n",
    "            nn.Conv2d(\n",
    "                in_channels, out_channels, kernel_size\n",
    "            ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "\n",
    "    def forward(self, x, digit):\n",
    "        print(\"Input shape\", x.shape)\n",
    "        disc_out = self.disc(x)\n",
    "        print(\"Disc out shape\", disc_out.shape)\n",
    "        print(\"Digit shape\", digit.shape)\n",
    "        digit = (digit-5)/10 # Normalize the digit to be between -0.4 and 0.4\n",
    "        linear = torch.cat((disc_out, digit.unsqueeze(1)), dim=1)\n",
    "        print(\"Linear shape\", linear.shape)\n",
    "        return self.out(linear)\n",
    "\n",
    "\n",
    "class MNISTGenerator(nn.Module):\n",
    "    def __init__(self, z_dim=100, channels_img=1, features_g=64):\n",
    "        super(MNISTGenerator, self).__init__()\n",
    "        self.gen = nn.Sequential(\n",
    "            self._block(z_dim, features_g * 16, 4, 1, 0),  # 4x4\n",
    "            self._block(features_g * 16, features_g * 8, 4, 2, 1),  # 8x8\n",
    "            self._block(features_g * 8, features_g * 4, 4, 2, 1),  # 16x16\n",
    "            nn.ConvTranspose2d(features_g * 4, channels_img, 4, 1, 0),  # 16x16\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.z_model = nn.Sequential(\n",
    "            nn.Linear(1, z_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(z_dim, z_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.digit_injector = nn.Sequential(\n",
    "            nn.Linear(1, z_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            nn.Linear(z_dim, z_dim),\n",
    "            nn.LeakyReLU(0.2),\n",
    "        )\n",
    "        self.z_dim = z_dim\n",
    "\n",
    "    def _block(self, in_channels, out_channels, kernel_size, stride, padding):\n",
    "        return nn.Sequential(\n",
    "            nn.ConvTranspose2d(in_channels, out_channels, kernel_size, stride, padding, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "\n",
    "    def forward(self, digit):\n",
    "        # Create an input vector for the generator, sized correctly (based on z_dim)\n",
    "        batch_size = digit.shape[0]\n",
    "\n",
    "        # Create a random vector of size z_dim\n",
    "        x = torch.randn(batch_size, self.z_dim, 1,1)\n",
    "\n",
    "        # Pass the random vector through the z_model\n",
    "        x = self.z_model(x)\n",
    "        # Add the digit to the random vector after passing it through the digit_injector\n",
    "        x = x + self.digit_injector(\n",
    "            ((digit-5)/10).unsqueeze(1)\n",
    "            ).unsqueeze(2).unsqueeze(3)\n",
    "        # Set the 0-th element to digit value\n",
    "        #x[:,0,0,0] = digit\n",
    "        fake_image = self.gen(x)\n",
    "        return fake_image\n",
    "    \n",
    "\n",
    "\n",
    "    # Create a GAN class that takes in the generator and discriminator, and the training data\n",
    "# The GAN class will be responsible for training the generator and discriminator\n",
    "# The GAN should train the generator to generate images of the digit that is fed as the input\n",
    "\n",
    "class GAN(nn.Module):\n",
    "    def __init__(self, generator, discriminator, trainset, testset, device='cpu', batch_size=32):\n",
    "        super(GAN, self).__init__()\n",
    "        self.trainset = trainset\n",
    "        self.testset = testset\n",
    "        self.device = device\n",
    "        self.batch_size = batch_size\n",
    "\n",
    "        self.generator = generator.to(device)\n",
    "        self.discriminator = discriminator.to(device)\n",
    "        self.criterion = nn.BCELoss()\n",
    "        self.d_optimizer = torch.optim.Adam(self.discriminator.parameters(), lr=0.002)\n",
    "        self.g_optimizer = torch.optim.Adam(self.generator.parameters(), lr=0.002)\n",
    "\n",
    "    def train_n_epochs(self, epochs, batch_size=32):\n",
    "        for epoch in range(epochs):\n",
    "            self._train_epoch(epoch, batch_size=batch_size)\n",
    "\n",
    "    def forward(self, digit):\n",
    "        return self.generate(digit)\n",
    "\n",
    "    def _train_epoch(self, epoch, batch_size=32):\n",
    "        self.generator.train()\n",
    "        self.discriminator.train()\n",
    "\n",
    "        mean_loss_d = 0\n",
    "        mean_loss_g = 0\n",
    "\n",
    "        for digits, real_images in DataLoader(self.trainset, batch_size=batch_size, shuffle=True):\n",
    "   \n",
    "            real_images = real_images.to(self.device)\n",
    "            digits = digits.to(self.device)\n",
    "\n",
    "            print(\"START\", digits.shape, real_images.shape)\n",
    "\n",
    "            real_labels = torch.ones(real_images.size(0), 1).to(self.device)\n",
    "            fake_labels = torch.zeros(real_images.size(0), 1).to(self.device)\n",
    "\n",
    "            # Train the discriminator\n",
    "            self.d_optimizer.zero_grad()\n",
    "\n",
    "            real_outputs = self.discriminator(real_images, digits.to(self.device))\n",
    "            # print(real_outputs.shape, real_labels.shape)\n",
    "            d_loss_real = self.criterion(real_outputs, real_labels)\n",
    "            d_loss_real.backward()\n",
    "\n",
    "            fake_images = self.generator(digits)\n",
    "            print(\"Fake images shape\", fake_images.shape)\n",
    "            fake_outputs = self.discriminator(fake_images, digits)\n",
    "            d_loss_fake = self.criterion(fake_outputs, fake_labels)\n",
    "            d_loss_fake.backward()\n",
    "\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "\n",
    "            self.d_optimizer.step()\n",
    "\n",
    "            # Train the generator\n",
    "            self.g_optimizer.zero_grad()\n",
    "\n",
    "            fake_images = self.generator(digits)\n",
    "            fake_outputs = self.discriminator(fake_images, digits)\n",
    "            g_loss = self.criterion(fake_outputs, real_labels) # We want the generator to generate images that the discriminator thinks are real\n",
    "            g_loss.backward()\n",
    "\n",
    "            self.g_optimizer.step()\n",
    "\n",
    "            mean_loss_d += d_loss.item()\n",
    "            mean_loss_g += g_loss.item()\n",
    "\n",
    "\n",
    "        _now_string = datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "        print(f'Time: {_now_string},Epoch {epoch}, D loss: {d_loss.item()}, G loss: {g_loss.item()}')\n",
    "\n",
    "        mean_loss_d /= len(self.trainset)\n",
    "        mean_loss_g /= len(self.trainset)\n",
    "\n",
    "        return mean_loss_d, mean_loss_g\n",
    "\n",
    "    def generate(self, digit):\n",
    "        self.generator.eval()\n",
    "        return self.generator(digit.to(self.device)).detach().cpu()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==========================================================================================\n",
      "Layer (type:depth-idx)                   Output Shape              Param #\n",
      "==========================================================================================\n",
      "MNISTGenerator                           [64, 1, 19, 63]           --\n",
      "├─Sequential: 1-1                        [64, 12, 1, 12]           180\n",
      "├─Sequential: 1-2                        [64, 12]                  180\n",
      "├─Sequential: 1-3                        [64, 1, 19, 63]           406,945\n",
      "==========================================================================================\n",
      "Total params: 407,305\n",
      "Trainable params: 407,305\n",
      "Non-trainable params: 0\n",
      "Total mult-adds (G): 9.26\n",
      "==========================================================================================\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 83.35\n",
      "Params size (MB): 1.63\n",
      "Estimated Total Size (MB): 84.98\n",
      "==========================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Create a GAN instance and train it\n",
    "\n",
    "generator = MNISTGenerator(z_dim=12, channels_img=1, features_g=12)\n",
    "discriminator = Discriminator(channels_img=1, features_d=4)\n",
    "\n",
    "gan = GAN(generator, discriminator, trainset, testset, device='cpu')\n",
    "\n",
    "print(summary(generator, input_size=(64,), device='cpu', depth=1))\n",
    "# summary(discriminator,input_size=((64,1,28,28), (64,)))\n",
    "# summary(gan, input_size=((64,), (64,)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "START torch.Size([64]) torch.Size([64, 1, 28, 28])\n",
      "Input shape torch.Size([64, 1, 28, 28])\n",
      "Disc out shape torch.Size([64, 225])\n",
      "Digit shape torch.Size([64])\n",
      "Linear shape torch.Size([64, 226])\n",
      "Fake images shape torch.Size([64, 1, 19, 63])\n",
      "Input shape torch.Size([64, 1, 19, 63])\n",
      "Disc out shape torch.Size([64, 300])\n",
      "Digit shape torch.Size([64])\n",
      "Linear shape torch.Size([64, 301])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (64x301 and 226x128)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[148], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Train the GAN\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mgan\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_n_epochs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[146], line 118\u001b[0m, in \u001b[0;36mGAN.train_n_epochs\u001b[0;34m(self, epochs, batch_size)\u001b[0m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain_n_epochs\u001b[39m(\u001b[38;5;28mself\u001b[39m, epochs, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m32\u001b[39m):\n\u001b[1;32m    117\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m epoch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(epochs):\n\u001b[0;32m--> 118\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[146], line 150\u001b[0m, in \u001b[0;36mGAN._train_epoch\u001b[0;34m(self, epoch, batch_size)\u001b[0m\n\u001b[1;32m    148\u001b[0m fake_images \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgenerator(digits)\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFake images shape\u001b[39m\u001b[38;5;124m\"\u001b[39m, fake_images\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m--> 150\u001b[0m fake_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdiscriminator\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfake_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdigits\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m d_loss_fake \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcriterion(fake_outputs, fake_labels)\n\u001b[1;32m    152\u001b[0m d_loss_fake\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/Documents/GitHub/hard-spheres/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/hard-spheres/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[146], line 44\u001b[0m, in \u001b[0;36mDiscriminator.forward\u001b[0;34m(self, x, digit)\u001b[0m\n\u001b[1;32m     42\u001b[0m linear \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((disc_out, digit\u001b[38;5;241m.\u001b[39munsqueeze(\u001b[38;5;241m1\u001b[39m)), dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLinear shape\u001b[39m\u001b[38;5;124m\"\u001b[39m, linear\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/hard-spheres/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/hard-spheres/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/hard-spheres/.venv/lib/python3.9/site-packages/torch/nn/modules/container.py:217\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    216\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 217\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    218\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m~/Documents/GitHub/hard-spheres/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/GitHub/hard-spheres/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/GitHub/hard-spheres/.venv/lib/python3.9/site-packages/torch/nn/modules/linear.py:116\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 116\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (64x301 and 226x128)"
     ]
    }
   ],
   "source": [
    "# Train the GAN\n",
    "gan.train_n_epochs(1, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 2024-05-04 23:04:19,Epoch 0, D loss: 0.05952277034521103, G loss: 3.204319715499878\n",
      "Time: 2024-05-04 23:06:31,Epoch 2, D loss: 0.37102529406547546, G loss: 2.69344162940979\n",
      "Time: 2024-05-04 23:08:42,Epoch 4, D loss: 0.27175742387771606, G loss: 2.390535593032837\n",
      "Time: 2024-05-04 23:10:47,Epoch 6, D loss: 0.5143649578094482, G loss: 2.214801549911499\n",
      "Time: 2024-05-04 23:12:52,Epoch 8, D loss: 0.5684919953346252, G loss: 1.423856258392334\n"
     ]
    }
   ],
   "source": [
    "# Train the GAN\n",
    "\n",
    "gan.train_n_epochs(10, 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time: 2024-05-04 23:15:55,Epoch 0, D loss: 1.2664172649383545, G loss: 0.7814494371414185\n",
      "Time: 2024-05-04 23:18:12,Epoch 2, D loss: 1.6521220207214355, G loss: 0.9710193276405334\n",
      "Time: 2024-05-04 23:20:30,Epoch 4, D loss: 0.8520565629005432, G loss: 1.512847900390625\n",
      "Time: 2024-05-04 23:22:46,Epoch 6, D loss: 1.3171820640563965, G loss: 0.9108135104179382\n",
      "Time: 2024-05-04 23:25:03,Epoch 8, D loss: 0.9192835688591003, G loss: 1.4069147109985352\n"
     ]
    }
   ],
   "source": [
    "# Train the GAN\n",
    "\n",
    "gan.train_n_epochs(10, 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(9-5)/10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fcfe7b9c040>"
      ]
     },
     "execution_count": 333,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Demo the GAN\n",
    "\n",
    "digit = torch.tensor([7])\n",
    "\n",
    "fake_images = gan(digit)\n",
    "\n",
    "plt.imshow(fake_images[0].squeeze().detach().numpy(), cmap='gray')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
