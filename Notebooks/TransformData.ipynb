{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transform data\n",
    "\n",
    "\n",
    "Transforms the datasets we have to .xyz format, so they are compatible with the CryinGAN repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "%cd ..\n",
    "\n",
    "from src.utils import load_raw_data, read_raw_sample\n",
    "\n",
    "%cd -\n",
    "\n",
    "def makedir_if_not_exists(path):\n",
    "    if not os.path.isdir(path):\n",
    "        print(\"Creating directory {}\".format(path))\n",
    "        os.mkdir(path)\n",
    "    return\n",
    "\n",
    "path = Path(\"../data/raw/samples\")\n",
    "\n",
    "\n",
    "phis = [0.84]\n",
    "files, dataframe, metadata = load_raw_data(path, phi=phis)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Path(file.replace(\"raw\", \"processed\")).parent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "max_files = 50 # Limit the amount of data\n",
    "\n",
    "processed_folder = Path(\"../data/processed/samples\")\n",
    "\n",
    "makedir_if_not_exists(processed_folder)\n",
    "\n",
    "# Dump as xyz with all data in a single file\n",
    "processed_file = Path(files[0].replace(\"raw\", \"processed\")).parent\n",
    "\n",
    "makedir_if_not_exists(str(processed_file.parent))\n",
    "\n",
    "\n",
    "os.remove(processed_file)\n",
    "\n",
    "with open(processed_file, \"a+\") as f:\n",
    "\n",
    "    for i, file in enumerate(files):\n",
    "        dataframe, metadata = read_raw_sample(file)\n",
    "\n",
    "        xyz = dataframe[[\"class\", \"x\", \"y\"]].reset_index(drop=True)\n",
    "\n",
    "        N = metadata.iloc[0,0] # N particles\n",
    "\n",
    "        xyz[\"z\"] = 0\n",
    "\n",
    "        xyz[\"class2\"] = xyz[\"class\"] # NOTE: This saves the files\n",
    "        xyz[\"class\"] = \"Cu\" # TODO: change to real atom symbols\n",
    "\n",
    "        f.write(f\"{N}\\n\")\n",
    "        # s = 'Properties=species:S:1:pos:R:3 pbc=\"F F F\"' # for extxyz format – unsure if correct\n",
    "        # f.write(s) # NOTE: Write this for extxyz format\n",
    "        f.write(\"\\n\")\n",
    "        f.flush()\n",
    "\n",
    "        xyz.to_csv(\n",
    "            processed_file,\n",
    "            header=False,\n",
    "            index=False, \n",
    "            sep=\"\\t\", \n",
    "            mode=\"a+\",\n",
    "            \n",
    "            )\n",
    "        \n",
    "        if i > max_files:\n",
    "            break\n",
    "        \n",
    "\n",
    "\n",
    "\n",
    "display(dataframe.head(10))\n",
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.io import read\n",
    "slab_from_file = read(processed_file, index=0, format=\"xyz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ase.visualize import view\n",
    "view(slab_from_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Works"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
