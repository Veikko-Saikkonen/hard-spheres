{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize CryinGAN training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "from matplotlib import pyplot as plt\n",
    "from ase.io import read, write\n",
    "from ase.visualize import view\n",
    "import numpy as np\n",
    "from glob import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT = \"../CCGAN/results/4-with-dist-extreme-weight\"\n",
    "EXPERIMENT = \"../CCGAN/results/3-with-dist-high-weight-long\"\n",
    "EXPERIMENT = \"../CCGAN/results/3-2-with-dist-high-weight-only-84\"\n",
    "EXPERIMENT_NAME = EXPERIMENT.split(\"/\")[-1]+\"/\" # Get the experiment name from the path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_runs = pd.read_csv(EXPERIMENT+\"/losses.csv\") # With distance discriminator 2\n",
    "run_starts = all_runs[\"epoch\"] == \"epoch\"\n",
    "\n",
    "# Filter out the rows that are not part of the runs\n",
    "# all_runs = all_runs[~run_starts]\n",
    "\n",
    "# Add \"run\" column\n",
    "all_runs[\"run\"] = 0\n",
    "\n",
    "run_idx = 0\n",
    "\n",
    "for i in range(1,len(all_runs)):\n",
    "    if run_starts[i]:\n",
    "        all_runs.loc[i:, \"run\"] = run_idx\n",
    "        run_idx += 1\n",
    "    else:\n",
    "        all_runs.loc[i, \"run\"] = run_idx\n",
    "\n",
    "print(\"Number of runs: \", all_runs[\"run\"].max() + 1)\n",
    "# Remove the first row of each run\n",
    "all_runs = all_runs[~run_starts]\n",
    "all_runs[\"epoch\"] = all_runs[\"epoch\"].astype(int)\n",
    "all_runs.set_index(\"epoch\", inplace=True)\n",
    "all_runs = all_runs.astype(float)\n",
    "\n",
    "# Read and visualize losses csv\n",
    "\n",
    "fig = plt.figure(figsize=(20,10))\n",
    "sns.lineplot(data=all_runs, figure=fig, marker=\"o\")\n",
    "# plt.grid(which=\"both\")\n",
    "plt.title(EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_df = pd.read_csv(f\"{EXPERIMENT}/learning_rate.csv\")\n",
    "lr_df.set_index(\"epoch\", inplace=True)\n",
    "lr_df = lr_df.astype(float)\n",
    "\n",
    "# Read and visualize learning rate csv\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(20,10))\n",
    "sns.lineplot(data=lr_df, marker=\"o\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check on the generated structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Numpy way from training-time generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_struct = read(\"../data/processed/samples/phi-0.84/samples.extxyz\", index=1, format=\"extxyz\")\n",
    "view(ref_struct,  viewer=\"x3d\", show_unit_cell=True, repeat=(1,1,1))\n",
    "\n",
    "atoms = ref_struct.copy()\n",
    "radii = atoms.get_array('rmt')\n",
    "\n",
    "plt.figure()\n",
    "plt.scatter(\n",
    "    atoms.get_scaled_positions()[:,0],\n",
    "    atoms.get_scaled_positions()[:,1],\n",
    "    c=radii,\n",
    "    s=radii*20,\n",
    "    alpha=0.5,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "latest_generated_sample = glob(f\"{EXPERIMENT}/gen_coords_*.npy\")\n",
    "latest_generated_sample.sort(key=lambda x: int(x.split(\"/\")[-1].split(\"_\")[2].split(\".\")[0]))\n",
    "latest_generated_sample = latest_generated_sample[-1]\n",
    "print(\"Latest generated sample: \", latest_generated_sample)\n",
    "\n",
    "file = latest_generated_sample\n",
    "# Or set manuall\n",
    "# file = f\"{EXPERIMENT}/gen_coords_60.npy\"\n",
    "\n",
    "np_coords = np.load(file)\n",
    "atoms = ref_struct.copy()\n",
    "\n",
    "# Pick a couple of structures to visualize\n",
    "idxs = [0, 1, 2]\n",
    "\n",
    "radii = atoms.get_array('rmt')\n",
    "\n",
    "for idx in idxs:\n",
    "    atoms.set_scaled_positions(np_coords[3,0]),\n",
    "    plt.figure()\n",
    "    plt.scatter(\n",
    "        atoms.get_scaled_positions()[:,0],\n",
    "        atoms.get_scaled_positions()[:,1],\n",
    "        c=radii,\n",
    "        s=radii*20,\n",
    "        alpha=0.5,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "atoms_list = []\n",
    "idx = 2 # Pick one generated sample\n",
    "\n",
    "file_list = glob(f\"{EXPERIMENT}/gen_coords_*.npy\")\n",
    "file_list = sorted(file_list, key=lambda x: int(x.split(\"_\")[-1].split(\".\")[0])) # Hack to sort in the right order\n",
    "\n",
    "for file in file_list:\n",
    "    np_coords = np.load(file)\n",
    "    atoms = ref_struct.copy()\n",
    "    atoms.set_scaled_positions(np_coords[idx].squeeze())\n",
    "\n",
    "    atoms_list.append(atoms)\n",
    "    # view(atoms, viewer=\"x3d\", show_unit_cell=True, repeat=(1,1,1))\n",
    "len(file_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.animation import FuncAnimation\n",
    "\n",
    "\n",
    "# Pick a good cmap\n",
    "plt.set_cmap(\"viridis\")\n",
    "\n",
    "\n",
    "lr_df = pd.read_csv(f\"{EXPERIMENT}/learning_rate.csv\")\n",
    "lr_df.set_index(\"epoch\", inplace=True)\n",
    "epochs = lr_df.index.values\n",
    "gen_lr = lr_df['generator_lr'].values\n",
    "coord_lr = lr_df['coord_disc_lr'].values\n",
    "dist_lr = lr_df['dist_disc_lr'].values\n",
    "\n",
    "cost_gen = all_runs.loc[lr_df.index,\"cost_gen\"].values\n",
    "\n",
    "n_frames = len(atoms_list)\n",
    "\n",
    "fig = plt.figure(figsize=(20, 15))\n",
    "gs  = gridspec.GridSpec(2, 2, height_ratios=[3, 1], hspace=0.3)\n",
    "\n",
    "# top row: two scatter plots\n",
    "ax_gen = fig.add_subplot(gs[0, 0])\n",
    "ax_ref = fig.add_subplot(gs[0, 1])\n",
    "\n",
    "# bottom row: learning-rate curve spanning both columns\n",
    "ax_lr  = fig.add_subplot(gs[1, :])\n",
    "\n",
    "\n",
    "def update(i):\n",
    "\n",
    "    current_epoch = epochs[i*20] # 20 epochs per frame\n",
    "    \n",
    "    # — Top: generated vs reference scatter plots —\n",
    "    ax_gen.clear()\n",
    "    ax_ref.clear()\n",
    "    \n",
    "    atoms = atoms_list[i]\n",
    "    radii = atoms.get_array(\"rmt\")\n",
    "    ax_gen.scatter(\n",
    "        atoms.get_scaled_positions()[:,0],\n",
    "        atoms.get_scaled_positions()[:,1],\n",
    "        c=radii, s=radii*20, alpha=0.5\n",
    "    )\n",
    "    ax_gen.set_title(\"Generated\")\n",
    "    \n",
    "    radii_ref = ref_struct.get_array(\"rmt\")\n",
    "    ax_ref.scatter(\n",
    "        ref_struct.get_scaled_positions()[:,0],\n",
    "        ref_struct.get_scaled_positions()[:,1],\n",
    "        c=radii_ref, s=radii_ref*20, alpha=0.5\n",
    "    )\n",
    "    ax_ref.set_title(\"Reference\")\n",
    "\n",
    "    # Set the same limits for both axes\n",
    "    ax_gen.set_xlim(-0.05, 1.05)\n",
    "    ax_gen.set_ylim(-0.05, 1.05)\n",
    "    ax_ref.set_xlim(-0.05, 1.05)\n",
    "    ax_ref.set_ylim(-0.05, 1.05)\n",
    "    \n",
    "    fig.suptitle(f\"Generated vs Reference — epoch {current_epoch}\")\n",
    "    \n",
    "    # — Bottom: all three LR curves + moving red line —\n",
    "    ax_lr.clear()\n",
    "    ax_lr.plot(epochs, gen_lr, label=\"Generator LR\",    linewidth=2)\n",
    "    ax_lr.plot(epochs, coord_lr, label=\"Coord Disc LR\", linewidth=2)\n",
    "    ax_lr.plot(epochs, dist_lr, label=\"Dist Disc LR\",   linewidth=2)\n",
    "\n",
    "    # Add another y axis for the generator cost\n",
    "    ax_cost_gen = ax_lr.twinx()\n",
    "    ax_cost_gen.plot(epochs, cost_gen, label=\"Generator cost\", color='orange', linewidth=2)\n",
    "    ax_cost_gen.set_ylabel(\"Generator cost\")\n",
    "\n",
    "    ax_lr.axvline(current_epoch, color='red', linestyle='--', linewidth=2)\n",
    "    \n",
    "    ax_lr.set_xlabel(\"Epoch\")\n",
    "    ax_lr.set_ylabel(\"Learning rate\")\n",
    "    ax_lr.set_title(\"Learning‐rate schedules\")\n",
    "    ax_lr.set_xlim(epochs.min(), epochs.max())\n",
    "    ax_lr.set_ylim(\n",
    "        min(gen_lr.min(), coord_lr.min(), dist_lr.min()),\n",
    "        max(gen_lr.max(), coord_lr.max(), dist_lr.max())\n",
    "    )\n",
    "\n",
    "    # Concatenate the legend entries from both axes\n",
    "    lines, labels = ax_lr.get_legend_handles_labels()\n",
    "    lines2, labels2 = ax_cost_gen.get_legend_handles_labels()\n",
    "    ax_lr.legend(lines + lines2, labels + labels2, loc='upper right')\n",
    "\n",
    "\n",
    "    # ax_lr.legend(loc='upper right')\n",
    "\n",
    "    \n",
    "# — Create and show the animation —\n",
    "ani = FuncAnimation(fig, update, frames=n_frames, interval=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ani.save(f\"{EXPERIMENT}/training.gif\", writer='pillow', fps=0.5)\n",
    "try:\n",
    "    ani.save(f\"{EXPERIMENT}/training.mp4\", writer='ffmpeg', fps=1, dpi=72) # Low dpi for fast export\n",
    "except:\n",
    "    print(\"ffmpeg not installed, skipping mp4 export\")\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "1. Provide Anshul with generated samples (50 each) in our data format\n",
    "   1. Low packing fraction 0.70\n",
    "   2. Mid 0.78\n",
    "   3. High packing fraction 0.84\n",
    "   4. Very high 0.86\n",
    "2. Special assignment: Try out different loss functions to make the generated structures more physically feasible (or something else)\n",
    "   1. Adding the bond distance discriminator\n",
    "   2. Radius / overlap loss\n",
    "   3. NN distance based loss\n",
    "   4. Hexatic (k=5) order loss\n",
    "   5. Other physical \n",
    "3. (Later: Conditioning on phi / other descriptors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
